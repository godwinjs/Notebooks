{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10344639,"sourceType":"datasetVersion","datasetId":6405895}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Generating Texts with Recurrent Neural Networks in Python\n#This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, LSTM, Dense, Activation\nfrom tensorflow.keras.optimizers import RMSprop\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfilepath = tf.keras.utils.get_file('shakespare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt' )\n# ReadBinary from filepath, decode with utf-8, transform to lowercase\ntext = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n\n# select some parts of the text\ntext = text[300000:800000]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-01T01:49:07.410987Z","iopub.execute_input":"2025-01-01T01:49:07.411338Z","iopub.status.idle":"2025-01-01T01:49:07.422398Z","shell.execute_reply.started":"2025-01-01T01:49:07.411312Z","shell.execute_reply":"2025-01-01T01:49:07.421156Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\n\ncharacters = sorted( set(text) )\nchar_to_index = dict(( c, i) for i, c in enumerate(characters) )\nindex_to_char = dict( (i, c) for i, c in enumerate(characters) )\n\nprint(char_to_index)\nprint(index_to_char)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T00:53:00.257395Z","iopub.execute_input":"2025-01-01T00:53:00.257836Z","iopub.status.idle":"2025-01-01T00:53:00.271965Z","shell.execute_reply.started":"2025-01-01T00:53:00.257805Z","shell.execute_reply":"2025-01-01T00:53:00.270756Z"}},"outputs":[{"name":"stdout","text":"{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38}\n{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'a', 14: 'b', 15: 'c', 16: 'd', 17: 'e', 18: 'f', 19: 'g', 20: 'h', 21: 'i', 22: 'j', 23: 'k', 24: 'l', 25: 'm', 26: 'n', 27: 'o', 28: 'p', 29: 'q', 30: 'r', 31: 's', 32: 't', 33: 'u', 34: 'v', 35: 'w', 36: 'x', 37: 'y', 38: 'z'}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"SEQ_LENGTH = 40\nSTEP_SIZE= 3\n\n# how ar\nsentences = []\n# complete e're you\nnext_characters = []\n\nfor i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE ):\n    sentences.append(text[i: i + SEQ_LENGTH])\n    next_characters.append(text[i + SEQ_LENGTH])\n\n# create numpy array\nx = np.zeros( (len(sentences), SEQ_LENGTH, len(characters)), dtype=bool )\ny = np.zeros( (len(sentences), len(characters)), dtype=bool )\n\n# Fill up the array with 2 for loops\nfor i, sentence in enumerate(sentences):\n    for t, character in enumerate(sentence):\n        x[ i, t, char_to_index[character] ] = 1\n    y[i, char_to_index[next_characters[i]] ] = 1\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T01:35:42.965309Z","iopub.execute_input":"2025-01-01T01:35:42.965636Z","iopub.status.idle":"2025-01-01T01:35:45.720888Z","shell.execute_reply.started":"2025-01-01T01:35:42.965613Z","shell.execute_reply":"2025-01-01T01:35:45.719834Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# feed training data to neural network\nmodel = Sequential()\n\n# long short term memory will remember the input few iterations ago\n# model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters)) ))\n\n# Add an Input layer\nmodel.add(InputLayer(shape=(SEQ_LENGTH, len(characters))))\n\n# Add an LSTM layer with 128 neurons\nmodel.add(LSTM(128))\n\nmodel.add(Dense(len(characters)))\n# predicting the best possible value by Adding an Activation layer with softmax\nmodel.add(Activation('softmax'))\n\n# learning_rate=0.01 - lr=0.01\nmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01) )\n\n# Train the model\nmodel.fit(x, y, batch_size=256, epochs=4 )\n\n# Save the model textpoetgenerator.keras - LTS or textpoetgenerator.h5 - backward compatibility\nmodel.save('textpoetgenerator.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T02:02:03.261552Z","iopub.execute_input":"2025-01-01T02:02:03.262099Z","iopub.status.idle":"2025-01-01T02:07:34.393770Z","shell.execute_reply.started":"2025-01-01T02:02:03.262068Z","shell.execute_reply":"2025-01-01T02:07:34.392468Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 117ms/step - loss: 2.4620\nEpoch 2/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 121ms/step - loss: 1.7598\nEpoch 3/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 140ms/step - loss: 1.5963\nEpoch 4/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 127ms/step - loss: 1.5133\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Check if the model file is present using !ls or os.listdir('.') to avoid FileNotFoundError\n# import os\n# os.listdir('.')\nmodel = tf.keras.models.load_model('textpoetgenerator.keras')\n\n#Helper function from keras tutorial for preds=predictions\n# takes model preds /high temp picks a more creative char.\ndef sample(preds, temperature=1.0):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds) \n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_text(length, temperature):\n    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n    generated = ''\n    sentence = text[start_index: start_index + SEQ_LENGTH ]\n    generated += sentence\n    for i in range(length):\n        x = np.zeros( (1, SEQ_LENGTH, len(characters)) )\n        for t, character in enumerate(sentence):\n            x[0, t, char_to_index[character] ] = 1\n            \n        prediction = model.predict(x, verbose=0)[0]\n        next_index = sample(prediction, temperature )\n        next_character = index_to_char[next_index]\n\n        generated += next_character\n        sentence = sentence[1:] + next_character\n    return generated\n\nprint('----poet temperature=0.2-----')\nprint(generate_text(300, 0.2))\n\nprint('----poet temperature=0.4-----')\nprint(generate_text(300, 0.4))\n\nprint('----poet temperature=0.6-----')\nprint(generate_text(300, 0.6))\n\nprint('----poet temperature=0.8-----')\nprint(generate_text(300, 0.8))\n\nprint('----poet temperature=1.0-----')\nprint(generate_text(300, 1.0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T02:45:52.099767Z","iopub.execute_input":"2025-01-01T02:45:52.100148Z","iopub.status.idle":"2025-01-01T02:47:53.293464Z","shell.execute_reply.started":"2025-01-01T02:45:52.100120Z","shell.execute_reply":"2025-01-01T02:47:53.291985Z"}},"outputs":[{"name":"stdout","text":"----poet temperature=0.2-----\nerence: throw away respect,\ntradition, for my lord, but the striff,\nand thou will not the world the married thee sound.\n\nking richard iii:\nwhat say the rest the crown of the seased\nthat he will be for the crown and the king\nhath see the words and the king of the king.\n\nking richard iii:\nwhat say the king here of the man and the crown.\n\nki\n----poet temperature=0.4-----\nand he himself not present? o, forfend is the words\nto the fears of thy love, what say for my wass\nthat sting the wing true of the rest with nownce\nto the crown to the crown to now hast thee have many\ndoth the king many father, and what tears,\nand and all this dead and the earth me soul\nthat see his son the king is strown.\n\nwarwick:\nof ma\n----poet temperature=0.6-----\n's neck,\nand then dreams he of cutting fair hands,\nwhat warwick and earth a swains a feast will\nthat though the fight to forth the mort; the love.\n\npaulina:\nand call i day that that duked be dead,\nand said seep the king here is is the crown;\nfor my lord, the king have be dead?\n\nking rtward king henry bolingbroke:\naway of his treess, for h\n----poet temperature=0.8-----\n-shining day,\ni spy a black, suspicious, my forth bote love\nmontrce can it his love!\n\nautolycus:\nas you, phillew mands' eyes, the griefs hard.\n\nking richard iii:\nmyself you have setten will ome time twory.\n\nking edward ive:\nad.\nand they and the fight weep god using cried\nmurgh for the lay on the down, letis prince,\nthe mackes the fire the\n----poet temperature=1.0-----\n two more summers wither in their pride,\ntherefore, lesty crance yourself you mays his end;\nwhat my ta, though in himself the'st alt;\nand noth for my know, i will youngb and resoth\nthe die with hate wow; whis, row shill feagh,\nmay, as a plives of his may;ilar,\nfor this troy; lad claling town of his;\nthere faindstence whe everset it thy me\n","output_type":"stream"}],"execution_count":30}]}
