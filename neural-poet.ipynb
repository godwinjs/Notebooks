{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f8fbfb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-01T02:57:04.241891Z",
     "iopub.status.busy": "2025-01-01T02:57:04.241412Z",
     "iopub.status.idle": "2025-01-01T02:57:16.639156Z",
     "shell.execute_reply": "2025-01-01T02:57:16.638006Z"
    },
    "papermill": {
     "duration": 12.405816,
     "end_time": "2025-01-01T02:57:16.641722",
     "exception": false,
     "start_time": "2025-01-01T02:57:04.235906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "filepath = tf.keras.utils.get_file('shakespare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt' )\n",
    "# ReadBinary from filepath, decode with utf-8, transform to lowercase\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "# select some parts of the text\n",
    "text = text[300000:800000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf211855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:57:16.649934Z",
     "iopub.status.busy": "2025-01-01T02:57:16.649050Z",
     "iopub.status.idle": "2025-01-01T02:57:16.663528Z",
     "shell.execute_reply": "2025-01-01T02:57:16.662189Z"
    },
    "papermill": {
     "duration": 0.02063,
     "end_time": "2025-01-01T02:57:16.665729",
     "exception": false,
     "start_time": "2025-01-01T02:57:16.645099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'a', 14: 'b', 15: 'c', 16: 'd', 17: 'e', 18: 'f', 19: 'g', 20: 'h', 21: 'i', 22: 'j', 23: 'k', 24: 'l', 25: 'm', 26: 'n', 27: 'o', 28: 'p', 29: 'q', 30: 'r', 31: 's', 32: 't', 33: 'u', 34: 'v', 35: 'w', 36: 'x', 37: 'y', 38: 'z'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "characters = sorted( set(text) )\n",
    "char_to_index = dict(( c, i) for i, c in enumerate(characters) )\n",
    "index_to_char = dict( (i, c) for i, c in enumerate(characters) )\n",
    "\n",
    "print(char_to_index)\n",
    "print(index_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c35c788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:57:16.673369Z",
     "iopub.status.busy": "2025-01-01T02:57:16.672884Z",
     "iopub.status.idle": "2025-01-01T02:57:19.422691Z",
     "shell.execute_reply": "2025-01-01T02:57:19.421235Z"
    },
    "papermill": {
     "duration": 2.756413,
     "end_time": "2025-01-01T02:57:19.425200",
     "exception": false,
     "start_time": "2025-01-01T02:57:16.668787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE= 3\n",
    "\n",
    "# how ar\n",
    "sentences = []\n",
    "# complete e're you\n",
    "next_characters = []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE ):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_characters.append(text[i + SEQ_LENGTH])\n",
    "\n",
    "# create numpy array\n",
    "x = np.zeros( (len(sentences), SEQ_LENGTH, len(characters)), dtype=bool )\n",
    "y = np.zeros( (len(sentences), len(characters)), dtype=bool )\n",
    "\n",
    "# Fill up the array with 2 for loops\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[ i, t, char_to_index[character] ] = 1\n",
    "    y[i, char_to_index[next_characters[i]] ] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ca4668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T02:57:19.433688Z",
     "iopub.status.busy": "2025-01-01T02:57:19.433058Z",
     "iopub.status.idle": "2025-01-01T03:02:30.903058Z",
     "shell.execute_reply": "2025-01-01T03:02:30.901438Z"
    },
    "papermill": {
     "duration": 311.476931,
     "end_time": "2025-01-01T03:02:30.905675",
     "exception": false,
     "start_time": "2025-01-01T02:57:19.428744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 118ms/step - loss: 2.5172\n",
      "Epoch 2/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 118ms/step - loss: 1.8030\n",
      "Epoch 3/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 120ms/step - loss: 1.6351\n",
      "Epoch 4/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 117ms/step - loss: 1.5362\n"
     ]
    }
   ],
   "source": [
    "# feed training data to neural network\n",
    "model = Sequential()\n",
    "\n",
    "# long short term memory will remember the input few iterations ago\n",
    "# model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters)) ))\n",
    "\n",
    "# Add an Input layer\n",
    "model.add(InputLayer(shape=(SEQ_LENGTH, len(characters))))\n",
    "\n",
    "# Add an LSTM layer with 128 neurons\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(len(characters)))\n",
    "# predicting the best possible value by Adding an Activation layer with softmax\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# learning_rate=0.01 - lr=0.01\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01) )\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=256, epochs=4 )\n",
    "\n",
    "# Save the model textpoetgenerator.keras - LTS or textpoetgenerator.h5 - backward compatibility\n",
    "model.save('textpoetgenerator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c57397b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T03:02:31.219839Z",
     "iopub.status.busy": "2025-01-01T03:02:31.219390Z",
     "iopub.status.idle": "2025-01-01T03:04:45.894911Z",
     "shell.execute_reply": "2025-01-01T03:04:45.893015Z"
    },
    "papermill": {
     "duration": 134.833369,
     "end_time": "2025-01-01T03:04:45.897333",
     "exception": false,
     "start_time": "2025-01-01T03:02:31.063964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----poet temperature=0.2-----\n",
      "remember me what a deal of world\n",
      "i wander the friends the friends of the dreads\n",
      "the world speak with the his loved and there is the sear\n",
      "the traitor with strike the brother of the dreads,\n",
      "and there is the friends and speak the friends\n",
      "and streas the fiest the his soul that with thee?\n",
      "\n",
      "polixenes:\n",
      "as i have thee the earth the dream to thee.\n",
      "----poet temperature=0.4-----\n",
      "\n",
      "nurse:\n",
      "even or odd, of all days in the sword,\n",
      "to the doom at the loventions, and thou art\n",
      "the world crown and the fither with the brother.\n",
      "\n",
      "flice: of york:\n",
      "why, a sonstreased with the world this will\n",
      "i have the sons be the sonsure the hearts\n",
      "and the mort me the friends and love the fair.\n",
      "\n",
      "henry bolingbroke:\n",
      "warwick, and when there nothin\n",
      "----poet temperature=0.6-----\n",
      "search, seek, and know how this foul murder,\n",
      "for this like a villain shall time my frow die.\n",
      "\n",
      "clown:\n",
      "in beseech the toom your paris,\n",
      "there nothing a desperant our songution,\n",
      "the partilane, i have repartast the such doth doth well.\n",
      "\n",
      "capulet:\n",
      "consting there i know a soul from this dead,\n",
      "and stail, i apperth of your tolguem\n",
      "here come is brea\n",
      "----poet temperature=0.8-----\n",
      "mus:\n",
      "i think there is not in the world eyes and thee\n",
      "that i am speak me\n",
      "that one thy brother ol dirtuted hither?\n",
      "o wifter is glught pithiny'd like with thy more;\n",
      "poor more, yet my dargeter, in love of they.\n",
      "\n",
      "somersay:\n",
      "me prices i should there love; and whot,\n",
      "that my spendle pleis and the lords to stear.\n",
      "\n",
      "queen:\n",
      "whither thou hang to are fl\n",
      "----poet temperature=1.0-----\n",
      "rit.\n",
      "but be it as it may: i here entail\n",
      "meas thou art ineaveg of mohely kins\n",
      "yey shalts parthatces beood more tothnes?\n",
      "to do see our holse beull it wax?\n",
      "\n",
      "clurben:\n",
      "willion for as lity us where ohtry aagees,\n",
      "cousin knave at villanines with thy waint::\n",
      "thou darst queen, with otte age am my, and better's sun ush.\n",
      "\n",
      "therk: too flick bur!\n",
      "as a p\n"
     ]
    }
   ],
   "source": [
    "# Check if the model file is present using !ls or os.listdir('.') to avoid FileNotFoundError\n",
    "# import os\n",
    "# os.listdir('.')\n",
    "model = tf.keras.models.load_model('textpoetgenerator.keras')\n",
    "\n",
    "#Helper function from keras tutorial for preds=predictions\n",
    "# takes model preds /high temp picks a more creative char.\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds) \n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH ]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x = np.zeros( (1, SEQ_LENGTH, len(characters)) )\n",
    "        for t, character in enumerate(sentence):\n",
    "            x[0, t, char_to_index[character] ] = 1\n",
    "            \n",
    "        prediction = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(prediction, temperature )\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n",
    "\n",
    "print('----poet temperature=0.2-----')\n",
    "print(generate_text(300, 0.2))\n",
    "\n",
    "print('----poet temperature=0.4-----')\n",
    "print(generate_text(300, 0.4))\n",
    "\n",
    "print('----poet temperature=0.6-----')\n",
    "print(generate_text(300, 0.6))\n",
    "\n",
    "print('----poet temperature=0.8-----')\n",
    "print(generate_text(300, 0.8))\n",
    "\n",
    "print('----poet temperature=1.0-----')\n",
    "print(generate_text(300, 1.0))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6405895,
     "sourceId": 10344639,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 467.113838,
   "end_time": "2025-01-01T03:04:48.760356",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-01T02:57:01.646518",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
